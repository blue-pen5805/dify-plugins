identity:
  name: chakoshi / Judge text API
  author: blue_pen5805
  label:
    en_US: chakoshi / Judge text API
description:
  human:
    en_US: Judge text
  llm: Judge text
parameters:
  - name: text
    type: string
    form: llm
    required: true
    label:
      en_US: text
    human_description:
      en_US: text
    llm_description: text
  - name: model
    type: string
    form: form
    required: false
    label:
      en_US: model name (optional)
    human_description:
      en_US: model name (optional)
    llm_description: model name (optional)
  - name: category_set_id
    type: string
    form: form
    required: false
    label:
      en_US: category set ID (optional)
    human_description:
      en_US: category set ID (optional)
    llm_description: category set ID (optional)
output_schema:
  type: object
  properties:
    flagged:
      type: boolean
      description: Whether any of the categories are flagged.
    unsafe_score:
      type: number
      description: A score that represents the level of unsafe content in the input.
    flagged_categories:
      type: array
      items:
        type: string
      description: A list of the categories that are flagged.
extra:
  python:
    source: tools/judge_text.py
